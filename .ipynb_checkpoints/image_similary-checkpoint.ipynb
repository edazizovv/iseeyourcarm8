{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST I: Using API from https://deepai.org/machine-learning-model/image-similarity\n",
    "\n",
    "# STATUS: WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 'C:/Users/MainUser/Desktop/deepai_APIkey.txt'\n",
    "crs = open(k, \"r\")\n",
    "for columns in (raw.strip().split() for raw in crs):\n",
    "    API_KEY = columns[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'distance': 32}, 'id': '591253a4-79d8-4642-bee3-6c123c57bc6b'}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(\n",
    "    \"https://api.deepai.org/api/image-similarity\",\n",
    "    files={\n",
    "        'image1': open('./image_similary/1_0.jpg', 'rb'),\n",
    "        'image2': open('./image_similary/1_1.jpg', 'rb'),\n",
    "    },\n",
    "    headers={'api-key': API_KEY}\n",
    ")\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'distance': 30}, 'id': 'bbf6a4af-6e3b-4ec1-8edb-80e61ee23f77'}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(\n",
    "    \"https://api.deepai.org/api/image-similarity\",\n",
    "    files={\n",
    "        'image1': open('./image_similary/1_0.jpg', 'rb'),\n",
    "        'image2': open('./image_similary/3_0.jpg', 'rb'),\n",
    "    },\n",
    "    headers={'api-key': API_KEY}\n",
    ")\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'output': {'distance': 26}, 'id': 'e7889323-8928-4ae5-976d-e26bbd99c4e5'}\n"
     ]
    }
   ],
   "source": [
    "r = requests.post(\n",
    "    \"https://api.deepai.org/api/image-similarity\",\n",
    "    files={\n",
    "        'image1': open('./image_similary/3_0.jpg', 'rb'),\n",
    "        'image2': open('./image_similary/3_2.jpg', 'rb'),\n",
    "    },\n",
    "    headers={'api-key': API_KEY}\n",
    ")\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST II: Using a Guide https://towardsdatascience.com/image-similarity-detection-in-action-with-tensorflow-2-0-b8d9a78b2509\n",
    "\n",
    "# STATUS: WORKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_image_feature_vectors.py#################################################\n",
    "# Imports and function definitions\n",
    "#################################################\n",
    "# For running inference on the TF-Hub module with Tensorflow\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub # For saving 'feature vectors' into a txt file\n",
    "import numpy as np # Glob for reading file names in a folder\n",
    "import glob\n",
    "import os.path\n",
    "##################################################################################################\n",
    "# This function:\n",
    "# Loads the JPEG image at the given path\n",
    "# Decodes the JPEG image to a uint8 W X H X 3 tensor\n",
    "# Resizes the image to 224 x 224 x 3 tensor\n",
    "# Returns the pre processed image as 224 x 224 x 3 tensor\n",
    "#################################################\n",
    "def load_img(path):# Reads the image file and returns data type of string\n",
    "    img = tf.io.read_file(path)# Decodes the image to W x H x 3 shape tensor with type of uint8\n",
    "    img = tf.io.decode_jpeg(img, channels=3)# Resizes the image to 224 x 224 x 3 shape tensor\n",
    "    img = tf.image.resize_with_pad(img, 224, 224)# Converts the data type of uint8 to float32 by adding a new axis\n",
    "    # img becomes 1 x 224 x 224 x 3 tensor with data type of float32\n",
    "    # This is required for the mobilenet model we are using\n",
    "    img = tf.image.convert_image_dtype(img,tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "    return img#################################################\n",
    "    # This function:\n",
    "    # Loads the mobilenet model in TF.HUB\n",
    "    # Makes an inference for all images stored in a local folder\n",
    "    # Saves each of the feature vectors in a file\n",
    "    #################################################\n",
    "def get_image_feature_vectors(from_dir, to_dir):\n",
    "\n",
    "    # Definition of module with using tfhub.dev\n",
    "    module_handle = \"https://tfhub.dev/google/imagenet/mobilenet_v2_140_224/feature_vector/4\"\n",
    "    # Loads the module\n",
    "    module = hub.load(module_handle)# Loops through all images in a local folder\n",
    "    \n",
    "    ## feature_bucket = []\n",
    "    for filename in glob.glob('{0}/*.jpg'.format(from_dir)):\n",
    "\n",
    "        print(filename)# Loads and pre-process the image\n",
    "        img = load_img(filename)# Calculate the image feature vector of the img\n",
    "        features = module(img)# Remove single-dimensional entries from the 'features' array  \n",
    "        feature_set = np.squeeze(features)\n",
    "\n",
    "        # Saves the image feature vectors into a file for later use\n",
    "        outfile_name = os.path.basename(filename) + \".npz\"\n",
    "\n",
    "        out_path = os.path.join(to_dir, outfile_name)# Saves the 'feature_set' to a text file\n",
    "        np.savetxt(out_path, feature_set, delimiter=',')\n",
    "        ## feature_bucked.append(feature_set)\n",
    "    ## return feature_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./image_similary\\1_0.jpg\n",
      "./image_similary\\1_1.jpg\n",
      "./image_similary\\1_2.jpg\n",
      "./image_similary\\3_0.jpg\n",
      "./image_similary\\3_1.jpg\n",
      "./image_similary\\3_2.jpg\n"
     ]
    }
   ],
   "source": [
    "from_dir = './image_similary'\n",
    "to_dir = './feature_similary'\n",
    "get_image_feature_vectors(from_dir, to_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy for loading image feature vectors from file\n",
    "import numpy as np\n",
    "\n",
    "# Time for measuring the process time\n",
    "import time\n",
    "\n",
    "# Glob for reading file names in a folder\n",
    "import glob\n",
    "import os.path\n",
    "\n",
    "# json for storing data in json file\n",
    "import json\n",
    "\n",
    "# Annoy and Scipy for similarity calculation\n",
    "from annoy import AnnoyIndex\n",
    "from scipy import spatial\n",
    "\n",
    "def cluster(to_dir):\n",
    "\n",
    "    start_time = time.time()\n",
    "\n",
    "    print(\"---------------------------------\")\n",
    "    print (\"Step.1 - ANNOY index generation - Started at %s\" %time.ctime())\n",
    "    print(\"---------------------------------\")\n",
    "\n",
    "    # Defining data structures as empty dict\n",
    "    file_index_to_file_name = {}\n",
    "    file_index_to_file_vector = {}\n",
    "\n",
    "    # Configuring annoy parameters\n",
    "    dims = 1792\n",
    "    n_nearest_neighbors = 20\n",
    "    trees = 10000\n",
    "\n",
    "    # Reads all file names which stores feature vectors \n",
    "    allfiles = glob.glob('{0}/*.npz'.format(to_dir))\n",
    "\n",
    "    t = AnnoyIndex(dims, metric='angular')\n",
    "\n",
    "    for file_index, i in enumerate(allfiles):\n",
    "\n",
    "        # Reads feature vectors and assigns them into the file_vector \n",
    "        file_vector = np.loadtxt(i)\n",
    "\n",
    "        # Assigns file_name, feature_vectors and corresponding product_id\n",
    "        file_name = os.path.basename(i).split('.')[0]\n",
    "        file_index_to_file_name[file_index] = file_name\n",
    "        file_index_to_file_vector[file_index] = file_vector\n",
    "\n",
    "        # Adds image feature vectors into annoy index   \n",
    "        t.add_item(file_index, file_vector)\n",
    "\n",
    "        print(\"---------------------------------\")\n",
    "        print(\"Annoy index     : %s\" %file_index)\n",
    "        print(\"Image file name : %s\" %file_name)\n",
    "        print(\"--- %.2f minutes passed ---------\" % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "    # Builds annoy index\n",
    "    t.build(trees)\n",
    "\n",
    "    print (\"Step.1 - ANNOY index generation - Finished\")\n",
    "    print (\"Step.2 - Similarity score calculation - Started \") \n",
    "\n",
    "    named_nearest_neighbors = []\n",
    "\n",
    "    # Loops through all indexed items\n",
    "    for i in file_index_to_file_name.keys():\n",
    "\n",
    "        # Assigns master file_name, image feature vectors and product id values\n",
    "        master_file_name = file_index_to_file_name[i]\n",
    "        master_vector = file_index_to_file_vector[i]\n",
    "\n",
    "        # Calculates the nearest neighbors of the master item\n",
    "        nearest_neighbors = t.get_nns_by_item(i, n_nearest_neighbors)\n",
    "\n",
    "        # Loops through the nearest neighbors of the master item\n",
    "        for j in nearest_neighbors:\n",
    "\n",
    "            print(j)\n",
    "\n",
    "            # Assigns file_name, image feature vectors and product id values of the similar item\n",
    "            neighbor_file_name = file_index_to_file_name[j]\n",
    "            neighbor_file_vector = file_index_to_file_vector[j]\n",
    "\n",
    "            # Calculates the similarity score of the similar item\n",
    "            similarity = 1 - spatial.distance.cosine(master_vector, neighbor_file_vector)\n",
    "            rounded_similarity = int((similarity * 10000)) / 10000.0\n",
    "\n",
    "            # Appends master product id with the similarity score \n",
    "            # and the product id of the similar items\n",
    "            named_nearest_neighbors.append({\n",
    "            'similarity': rounded_similarity,\n",
    "            'master_pi': master_file_name,\n",
    "            'similar_pi': neighbor_file_name})\n",
    "\n",
    "    print(\"---------------------------------\") \n",
    "    print(\"Similarity index       : %s\" %i)\n",
    "    print(\"Master Image file name : %s\" %file_index_to_file_name[i]) \n",
    "    print(\"Nearest Neighbors.     : %s\" %nearest_neighbors) \n",
    "    print(\"--- %.2f minutes passed ---------\" % ((time.time() - start_time)/60))\n",
    "\n",
    "\n",
    "    print (\"Step.2 - Similarity score calculation - Finished \") \n",
    "\n",
    "    # Writes the 'named_nearest_neighbors' to a json file\n",
    "    with open('nearest_neighbors.json', 'w') as out:\n",
    "        json.dump(named_nearest_neighbors, out)\n",
    "\n",
    "    print (\"Step.3 - Data stored in 'nearest_neighbors.json' file \") \n",
    "    print(\"--- Prosess completed in %.2f minutes ---------\" % ((time.time() - start_time)/60))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "Step.1 - ANNOY index generation - Started at Sat Aug  1 02:22:04 2020\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "Annoy index     : 0\n",
      "Image file name : 1_0\n",
      "--- 0.00 minutes passed ---------\n",
      "---------------------------------\n",
      "Annoy index     : 1\n",
      "Image file name : 1_1\n",
      "--- 0.00 minutes passed ---------\n",
      "---------------------------------\n",
      "Annoy index     : 2\n",
      "Image file name : 1_2\n",
      "--- 0.00 minutes passed ---------\n",
      "---------------------------------\n",
      "Annoy index     : 3\n",
      "Image file name : 3_0\n",
      "--- 0.00 minutes passed ---------\n",
      "---------------------------------\n",
      "Annoy index     : 4\n",
      "Image file name : 3_1\n",
      "--- 0.00 minutes passed ---------\n",
      "---------------------------------\n",
      "Annoy index     : 5\n",
      "Image file name : 3_2\n",
      "--- 0.00 minutes passed ---------\n",
      "Step.1 - ANNOY index generation - Finished\n",
      "Step.2 - Similarity score calculation - Started \n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "1\n",
      "0\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "2\n",
      "0\n",
      "1\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "1\n",
      "0\n",
      "2\n",
      "5\n",
      "4\n",
      "3\n",
      "1\n",
      "0\n",
      "2\n",
      "5\n",
      "5\n",
      "3\n",
      "1\n",
      "4\n",
      "0\n",
      "2\n",
      "---------------------------------\n",
      "Similarity index       : 5\n",
      "Master Image file name : 3_2\n",
      "Nearest Neighbors.     : [5, 3, 1, 4, 0, 2]\n",
      "--- 0.01 minutes passed ---------\n",
      "Step.2 - Similarity score calculation - Finished \n",
      "Step.3 - Data stored in 'nearest_neighbors.json' file \n",
      "--- Prosess completed in 0.01 minutes ---------\n"
     ]
    }
   ],
   "source": [
    "cluster(to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
